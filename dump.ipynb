{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE TO LOAD MAX-MIN POOLED MFCC FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaiye Meharban - Howrah Bridge 1958 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Aaja Aaja - Yeh Raaste Hain Pyaar Ke 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Aao Huzoor Tumko - Kismet 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Aasmaa - Saand Ki Aankh 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Aise Jalta Hai Jiya - 1920 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Allahu - Dev 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Andhere - 31st October 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Ankh Milaoongi - Fiza 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Baila Baila - Khwahish 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Bhanwara Bada Nadan Asha Bhosle - Sahib Bibi Aur Ghulam 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_MKS 1978 - O Saathi Re Tere Bina-Female_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_MS 1966 - Jhumka Gira Re_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_Rangeela 1995 - Tanha Tanha Yahan Pe_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_STK 1982 - Kitne Bhi Tu(Female)_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_UJ 1981 - Dil Cheez Kya Hai_MFCC.csv\n",
      "(20, 25000)\n",
      "bollywood_UJ 1981 - In Aankhon Ki Masti Ke_MFCC.csv\n",
      "(20, 25000)\n",
      "Chain Aapko Mila - Footpath 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Chup Chup - Grahan 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Dhuan Dhuan - Meenaxi 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Dil Dhoonde  - Soch 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Dil Jhanjhanale Jaane Jaana - Chhal 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Dilbar Dilbar - Rishtey 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Filhaal - Filhaal 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Hey Rama Krishna - Mast 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "In Ankhon Ki Masti - Umrao Jaan (1981) 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Janeman Janeman - Kaho Naa Pyar Hai 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Jo Huwa Woh Huwa Kis Liye (Album Version) - Dil Kahin Hosh Kahin 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Jung Ho Ya Pyar - Kranti 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Kaafi Nahi Chaand - Revolver Rani 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Koi Shahri Babu - Loafer 1973 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Lamha Lamha Zindagi Hai  - Corporate 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Lucky Lips - Lucky No Time For Love 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Maar Gayo Re - Sandhya_MFCC.csv\n",
      "(20, 25000)\n",
      "Maria  - Aankhon Mein Sapne Liye 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Na Govinda - Mast 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Naam Chalka-E-Jaam  - Badmaash 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "new_320_05 - Ankh Milaoongi - Fiza (2000)_MFCC.csv\n",
      "(20, 25000)\n",
      "new_320_05 - Janeman Janeman - KNPH (2000)_MFCC.csv\n",
      "(20, 25000)\n",
      "old_AA40C - Khatooba Khatooba_MFCC.csv\n",
      "(20, 25000)\n",
      "old_Andaz-Zindagi Ek Safar Hai (2)_MFCC.csv\n",
      "(20, 25000)\n",
      "old_APHG-Thoda Sa Pagla Thoda_MFCC.csv\n",
      "(20, 25000)\n",
      "old_don-Yeh mera dil yaar ka deewana_MFCC.csv\n",
      "(20, 25000)\n",
      "old_Loafer-Koi Shehri Babu_MFCC.csv\n",
      "(20, 25000)\n",
      "old_Lootmaar-Jab Chaye Mera_MFCC.csv\n",
      "(20, 25000)\n",
      "old_Shaan-Pyar Karne Wale_MFCC.csv\n",
      "(20, 25000)\n",
      "Prem Mein Tohre- Begum Jaan 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Sharaabiyon - Teesri Aankh 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Sone Jaisi Teri Jawani - Maa Tujhhe Salaam 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Thodasa Pagla - Aur Pyar Ho Gaya 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Yeh Kaisa Utthaan Hai Female  - Utthaan 128 Kbps_MFCC.csv\n",
      "(20, 25000)\n",
      "Aala_Aala_Vara_From_Ha_Khel_Sawalyancha_Asha_Bhosle_Anuradha_Paudwal_mfcc.csv\n",
      "(20, 25000)\n",
      "Aale Manat Majhya (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Ajan Amhi Tujhi Lekare (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Akashi_Zep_Ghe_Re_Pakhara_With_Lyrics_आकाशी_झेप_घे_रे_पाखरा_Sudhir_mfcc.csv\n",
      "(20, 25000)\n",
      "Akhercha_Ha_Tula_Dandvat_From_Maratha_Tituka_Melvava_Lata_Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Bai-Mi-Patang-Udvit-Hote-From-Lakhat-Ashi-Dekhni-Asha-Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Bhatukalichya_Khela_Madhali_Raja_with_lyrics_भातुकलीच्या_खेळामधली_mfcc.csv\n",
      "(20, 25000)\n",
      "Bhet_Tujhi_Majhi_Smarate_with_lyrics_भेट_तुझी_माझी_स्मरते_Arun_Date_mfcc.csv\n",
      "(20, 25000)\n",
      "Chandoba_Chandoba_Bhaglas_Ka_Chandomama_Chandomama_Bhaglas_Ka_Marathi_mfcc.csv\n",
      "(20, 25000)\n",
      "Chandra Che Chandane Janu Hi (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Chiv_Chiv_Chimni_in_3D_Marathi_3D_Rhymes_Marathi_Balgeet_Song_मराठी_mfcc.csv\n",
      "(20, 25000)\n",
      "Daiva-Janile-Kuni-From-Molkarin-Lata-Mangeshkar (1)_mfcc.csv\n",
      "(20, 25000)\n",
      "Daiva-Janile-Kuni-From-Molkarin-Lata-Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Dayaghana-From-Sansar-Suresh-Wadkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Dhundi-Kalyana-From-Dhakat-Bahin-Sudhir-Phadke-Asha-Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Dhundit_Gau_Mastit_Raahu_From_Bala_Gaun_Kashi_Angaai_Asha_Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Ek_Zoka_Chuke_Kaljacha_Thoka_एक_झोका_चुके_काळजाचा_ठोका_Asha_Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Gela-Sodun-Majasi-Kanha-From-Songadya-Suman-Kalyanpur_mfcc.csv\n",
      "(20, 25000)\n",
      "Gomu_Sangtina_Mazya_From_Ha_Khel_Sawalyancha_Hemanta_Mukherjee_Asha_mfcc.csv\n",
      "(20, 25000)\n",
      "Ha-Khel-Sawalyancha-From-Ha-Khel-Sawalyancha-Mahendra-Kapoor_mfcc.csv\n",
      "(20, 25000)\n",
      "Has Re Rhrudayi Mam Nandlal (Album Version) - (Raag.Fm) (1)_mfcc.csv\n",
      "(20, 25000)\n",
      "Has Re Rhrudayi Mam Nandlal (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Hasnya Che Bahumol (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Hi_Vaat_Door_Jaate_with_lyrics_ही_वाट_दूर_जाते_Asha_Bhosle_Pt_Hridaynath_mfcc.csv\n",
      "(20, 25000)\n",
      "Jhuk_Jhuk_Gadi_झुक_झुक_गाडी_Marathi_Balgeet_Marathi_Badbad_Geete_mfcc.csv\n",
      "(20, 25000)\n",
      "Jivalaga_rahile_re_door_ghar_maze_with_lyrics_जिवलगा_राहिले_रे_दूर_mfcc.csv\n",
      "(20, 25000)\n",
      "Jivanath-Hi-Ghadi-From-Kamapurta-Mama-Lata-Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Kaajal-Raatina-From-Ha-Khel-Sawalyancha-Asha-Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Kaal_Rateela_Sapan_Padlan_From_Ekta_Jeev_Sadashiv_Jaywant_Kulkarni_mfcc.csv\n",
      "(20, 25000)\n",
      "Kadhi-Kadhi-From-Irada-Pakka-Javed-Ali_mfcc.csv\n",
      "(20, 25000)\n",
      "Kal Ratri Swapna Madhe (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Kashi_Nashibana_Thatta_Aaj_Mandali_with_lyrics_कशी_नशीबाने_थट्टा_mfcc.csv\n",
      "(20, 25000)\n",
      "Latpat-Latpat-From-Amar-Bhoopali-Lata-Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Malmali-Tarunya-Maaze-From-Gharkul-Asha-Bhosle (1)_mfcc.csv\n",
      "(20, 25000)\n",
      "Malmali-Tarunya-Maaze-From-Gharkul-Asha-Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Mamachya_Gavala_Jauya_Zuk_zuk_Aagingadi_Top_Marathi_Balgeet_Marathi_mfcc.csv\n",
      "(20, 25000)\n",
      "Nindati He Lok Jari Ho (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Om Namo Ha Sur Jithe Rangato (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Pikala_Jambhul_Todu_Naka_From_Bot_Lavin_Tithe_Gudgulya_Usha_Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Preeticha_Zul_Zul_Paani_From_Banya_Bapu_Usha_Mangeshkar_Shailendra_mfcc.csv\n",
      "(20, 25000)\n",
      "Reshmachya-Reghani-From-Maratha-Tituka-Melvava-Asha-Bhosle_mfcc.csv\n",
      "(20, 25000)\n",
      "Sang_sang_Bholanath_Marathi_balgeet_for_children_सांग_सांग_भोलानाथ_mfcc.csv\n",
      "(20, 25000)\n",
      "sasa_re_sasa_ससा_रे_ससा_Sasa_Kasav_Hair_Tortoise_Marathi_JingleToonsMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Shodhu_Mee_Kuthe_From_Naav_Mothan_Lakshan_Khotan_Lata_Mangeshkar_mfcc.csv\n",
      "(20, 25000)\n",
      "Shree Ranga Ho Dhyas Jivala (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Tumhavar_Keli_Mee_Marji_Bahaal_with_lyrics_तुम्हावर_केली_मी_मर्जी_mfcc.csv\n",
      "(20, 25000)\n",
      "Valhav Re Valhav Re Hodi (Album Version) - (Raag.Fm)_mfcc.csv\n",
      "(20, 25000)\n",
      "Ya_chimanyano_with_lyrics_या_चिमण्यांनो_Lata_MangeshkarMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Ye_Re_Ye_Re_Pavasa_Tula_Deto_Paisa_Marathi_Rhymes_For_Children_Marathi_mfcc.csv\n",
      "(20, 25000)\n",
      "नाच_रे_मोरा_Nach_Re_Mora_Marathi_Balgeet_Marathi_Rain_Song_Popular_mfcc.csv\n",
      "(20, 25000)\n",
      "128-Aise Na Mujhe - Darling Darling 128 Kbps_mfcc.csv\n",
      "(20, 25000)\n",
      "bollywood_MI 1987 - Zindagi Ki Yahi Reet Hai_mfcc.csv\n",
      "(20, 25000)\n",
      "bollywood_MKS 1978 - O Saathi Re Tere Bina_mfcc.csv\n",
      "(20, 25000)\n",
      "bollywood_MKS 1978 - Rote Hue Aate Hai Sab_mfcc.csv\n",
      "(20, 25000)\n",
      "bollywood_Nazrana-Isse Pehle Ke Yaad Tu Aaye_mfcc.csv\n",
      "(20, 25000)\n",
      "Chanda_O_Chanda_Kishore_Kumar_Mehmood_Lakhon_Mein_Ek_SongMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Ghungroo_Ki_Tarah_Shashi_Kapoor_Chor_Machaye_Shor_SongMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Jaise_Ko_Taisa_Mila_Jeetendra_Ramesh_Deo_Jaise_Ko_Taisa_SongMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Lo_Main_Ban_Gaya_Thanedar_Amitabh_Bachchan_Inquilaab_SongMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Nadiya_Se_Dariya_Rajesh_Khanna_Kishore_Kumar_Namak_Haraam_SongMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Amar Prem-kuch to log kahenge_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Andaz-Zindagi Ek Safar Hai_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Anokhi Ada-Haal Kya Hai Dilon Ka_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Anurodh-Aate Jaate Khoobsurat_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Aradhana-Mere Sapno Ki Rani Kab_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Aradhana-Roop Tera Mastana_mfcc.csv\n",
      "(20, 25000)\n",
      "old_CC-Chalte Chalte Mere Yeh Geet_mfcc.csv\n",
      "(20, 25000)\n",
      "old_don-Are Diwano Mujhe Pehchano_mfcc.csv\n",
      "(20, 25000)\n",
      "old_dream girl-Dream Girl_mfcc.csv\n",
      "(20, 25000)\n",
      "old_ek_ajnabee_haseena_se_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Golmaal-Aanewala Pal_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Imtihan-Ruk Jaana Nahin(3)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Julie-Dil Kya Kare_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_Kumar_collection (1)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_Kumar_collection (29)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_Kumar_collection (51)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_Kumar_collection (67)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_Kumar_collection_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_kumar_solo (23)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_kishore_kumar_solo (25)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Kudrat-Humen Tumse Pyar_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Manzil-Rim Jhim Gire Saawan_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Mehbooba-Mere Naina Saawan_mfcc.csv\n",
      "(20, 25000)\n",
      "old_MJS-Chala Jata Hoon (1)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_MJS-Chala Jata Hoon_mfcc.csv\n",
      "(20, 25000)\n",
      "old_MXIB-Mere Mehboob Qayamat Hogi_mfcc.csv\n",
      "(20, 25000)\n",
      "old_NH-Pag Ghungroo Bandh_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Padosan-Mere Samnewali_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Parichay-Musafir Hoon Yaaron_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Saagar-Sagar Jaisi Aankhon Wali_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Safar - Zindagi Ka Safar Hai_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Shalimar-hum bewafa-1_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Sharabi-de de pyar de(male)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Sholay-koi haseena jab_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Souten -Zindagi Pyar Ka(male)_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Yaarana-Bhole O Bhole_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Yaarana-Chhukar Mere Man Ko_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Yaarana-Sara Zamana_mfcc.csv\n",
      "(20, 25000)\n",
      "old_Yaarana-Tere Jaisa Yaar Kahan_mfcc.csv\n",
      "(20, 25000)\n",
      "O_Nigaahe_Mastaana_Dev_Anand_Nutan_Kishore_Kumar_Paying_Guest_Old_mfcc.csv\n",
      "(20, 25000)\n",
      "Aase_Wajwa_Ki_Dholki_Siddharth_Jadhav_Manasi_Naik_Lavani_MandaliMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Aho_Sheth_Lay_Disan_Jhaliya_Bhet_Sheth_Lavani_Hiryachi_Angathi_Sonali_mfcc.csv\n",
      "(20, 25000)\n",
      "Amhi_Nahi_Ja_Lavani_Song_Ideachi_Kalpana_Marathi_Lavani_Songs_Swapnil_mfcc.csv\n",
      "(20, 25000)\n",
      "Apsara_Aali_Full_Song_Natarang_Sonalee_Kulkarni_Ajay_Atul_Marathi_mfcc.csv\n",
      "(20, 25000)\n",
      "Ardhya_Ratrila_Koti_Bela_Shende _Harshada_Bhavsar_Divesh_Medage_mfcc.csv\n",
      "(20, 25000)\n",
      "Baghun_Mala_Zala_Pavna_Yeda_Official_Video_Bugadi_Maazi_Sandali_mfcc.csv\n",
      "(20, 25000)\n",
      "Chadhavila_Patta_Kamarevari_Phulrani_Subodh_B_Priyadarshini_Vaishnavi_mfcc.csv\n",
      "(20, 25000)\n",
      "Chandra_Official_Song_Chandramukhi_Marathi_Song_2022_Ajay_Atul_feat_mfcc.csv\n",
      "(20, 25000)\n",
      "Darawar_Tichki_Maara_Chhand_Priticha_Subodh_Bhave_Harsh_Kulkarni_mfcc.csv\n",
      "(20, 25000)\n",
      "Dholkichya_Talavar_Lavni_ढोलकीच्या_तालावर_लावणी_STKMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Dolyavar_Gogal_Lava_Bhirkit_Akshada_P_Girish_K_Tanaji_G_Urmila_D_mfcc.csv\n",
      "(20, 25000)\n",
      "English_Shikvun_Soda_Full_Video_Ghuma_Vaishali_Jadhav_Priyanka_BarveMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Fantastic_Lavani_Lyrical_Video_Sanskruti_Balgude_Sanngto_Aika_Landmarc_mfcc.csv\n",
      "(20, 25000)\n",
      "Guljaar_Lavni_Sandook_Urmila_Dhangar_Ajit_SameerMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Ishakacha_Baan_Taleem_Ronkini_Gupta_Swapnil_Godbole_Praful_KarlekarMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Ishkacha_Gulkand_Best_Lavani_Aishwarya_Seema_Kale_Apsara_Ali_Zee_mfcc.csv\n",
      "(20, 25000)\n",
      "Kashi_Mi_Jau_Mathurechya_Bajari_Natarang_Atul_Kulkarni_Ajay_AtulMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Kashyala_Lavato_Lavani_Song_Poshter_Girl_Superhit_Marathi_Song_Rasika_mfcc.csv\n",
      "(20, 25000)\n",
      "Kata_Rutla_Lavani_Dance_Yedyanchi_Jatra_Shweta_Tiwari_Step_In_Art_mfcc.csv\n",
      "(20, 25000)\n",
      "Lyrical_Mala_Jau_De_Ferrari_Ki_Sawaari_Vidya_Balan_Urmila_Dhangar_mfcc.csv\n",
      "(20, 25000)\n",
      "Madanmanjiri_Phullwanti_Prajaktta_Mali_Gashmeer_Mahajani_Vaishali_mfcc.csv\n",
      "(20, 25000)\n",
      "Main_Kolhapur_Se_Aayi_Hoon_Madhuri_Dixit_Lavni_Dance_Anjaam_Full_mfcc.csv\n",
      "(20, 25000)\n",
      "Majha_Jwanila_Nivdung_Bhushan_Pradhan_Sanskruti_Balgude_Urmila_Dhangar_mfcc.csv\n",
      "(20, 25000)\n",
      "Mala_Bheta_Na_Dupari_Full_Video_Fandi_Shradha_Chavhan_Bela_Shende_mfcc.csv\n",
      "(20, 25000)\n",
      "Mala_Jau_De_Full_Song_Vidya_Balan_Ferrari_Ki_SawaariMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Mi_Karte_Tumhala_Mujra_With_Lyrics_Marathi_Song_Gautami_Patil_New_mfcc.csv\n",
      "(20, 25000)\n",
      "Mohrachya_Daravar_Song_Movie_Baban_Marathi_Songs_2018_Sunidhi_Chauhan_mfcc.csv\n",
      "(20, 25000)\n",
      "Nad_Khula_Master_Eke_Master_Lavani_Marathi_Song_Sumeet_MusicMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Natle_Tumchya_Sathi_Surekha_Punekar_Lavni_नटले_तुमच्या_साठी_लावणी_mfcc.csv\n",
      "(20, 25000)\n",
      "Pahate_Che_Pach_Full_Video_Chhand_Priticha_Subodh_Bhave_Harsh_Kulkarni_mfcc.csv\n",
      "(20, 25000)\n",
      "Paul_Padla_Chorich_Jalsa_Girija_Joshi_Ashutosh_S_Raaj_Nikhil_WairagarMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Petala_Lal_Diva_Bandishala_Vaishali_Samant_Krutika_G_Sharad_Ponkshe_mfcc.csv\n",
      "(20, 25000)\n",
      "Pikala_Jambhul_Todu_Naka_पिकलं_जांभूळ_तोडू_नका_Marathi_Lavani_Dada_mfcc.csv\n",
      "(20, 25000)\n",
      "Rati_Ardhya_Raati_Marathi_Lyrical_Video_Bela_Shinde_Marathi_LavaniMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Sawaal_Jawaab_Full_Video_Chhand_Priticha_Subodh_B_Vikas_S_Suvarna_mfcc.csv\n",
      "(20, 25000)\n",
      "Shahiri_Lavni_Full_Video_Chhand_Priticha_Suvarna_Kale_Harsh_Kulkarni_mfcc.csv\n",
      "(20, 25000)\n",
      "Tumhi_Yetana_Kela_Eshara_Full_Video_Farzand_Mrunmayee_Deshpande_mfcc.csv\n",
      "(20, 25000)\n",
      "Ugavali_Shukrachi_Chandani_De_Dhakka_Full_Song_Aarati_Ankalikar_mfcc.csv\n",
      "(20, 25000)\n",
      "Vaadhiv_Distay_Rao_Chatrapati_Shasan_Kiran_Kore_Urmila_DhangarMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Vichar_Kay_Hay_Tumcha_Surekha_Punekar_Lavni_विचार_काय_आहे_तुमचा_mfcc.csv\n",
      "(20, 25000)\n",
      "Wajle_Ki_Bara_Natarang_Amruta_Khanvilkar_Ajay_Atul_Lavani_SongsMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Yo Kash Tashe - Lavani Maharashtrachi- Vol.1(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "_Fantastic_Lavani_song_Sanskruti_Balgude_Sanngto_Aika_Marathi_MovieMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "खेळ_इश्काचा_जपून_खेळा_Khel_Ishqacha_Japun_Khela_Romantic_Lavani_mfcc.csv\n",
      "(20, 25000)\n",
      "खेळताना_रंग_बाई_होळीचा_Kheltana_Rang_Bai_Holicha_Shakuntala_Jadhav_mfcc.csv\n",
      "(20, 25000)\n",
      "चैत्राली_राजे_लावणी_कैरी_पाडाची_Chaitrali_raje_lavani_kairi_padachi_mfcc.csv\n",
      "(20, 25000)\n",
      "बँड_वाल्या_बँड_तुझा_वाजु_दे_Anand_Shinde_Rahul_Patil_Dev_Chauhan_mfcc.csv\n",
      "(20, 25000)\n",
      "बुगडी_माझी_सांडली_गं_Bugadi_Majhi_Sandali_Ga_Jayshree_Gadkar_Marathi_mfcc.csv\n",
      "(20, 25000)\n",
      "मला_पिरतिच्या_झुल्यात_झुलवा_मराठी_लावणी_गीत_MALA_PIRTICHYA_AIYAA_mfcc.csv\n",
      "(20, 25000)\n",
      "मी_साताऱ्याची_गुलछडी_मला_रोखून_पाहू_नका_Resham_Tipnis_Bharat_Jadhav_mfcc.csv\n",
      "(20, 25000)\n",
      "रूपान_देखणी_Rupaan_Dekhani_Pachadlela_Lavani_Song_Performed_By_Megha_mfcc.csv\n",
      "(20, 25000)\n",
      "सोळावं_वरीस_धोक्याचं_Solava_Varis_Dhokyacha_Lavani_Sulochana_C_Jayshree_mfcc.csv\n",
      "(20, 25000)\n",
      "In_The_Closet_Michael_Jackson_solo_version_edited_MichaelJacksonMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson  - Someone In The Dark(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson  -Thriller - Baby Be Mine(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Bad (Extended Version)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Bad (Shortened Version)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Beat It (Official 4K Video)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Beat It _ MJWE Mix 2011(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Billie Jean (Official Video)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Billie Jean (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Billie_Billy Jean (Live)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Come Together (Official Video)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Cry (Official Video)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Cry (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Dangerous (Audio)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Dangerous - She Drives Me Wild(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Dirty Diana (Official Video)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Dirty Diana (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Earth Song (Acapella)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Earth Song (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Give In To Me (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Happy(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Heal The World (Official Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Lovely One - Osaka 1987(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Speechless Lyrics(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Sunset driver- Michael Jackson(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Thriller (Lyrics)(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Thriller (Official 4K Video)(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson - Thriller - Thriller(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael Jackson _Got To Be There_(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Another_Part_of_Me_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Billie_Jean_Live_at_the_MTV_Video_Music_Awards_1995_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Black_Or_White_Official_Video_Shortened_VersionMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Dangerous_Live_Munich_1997_HDMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Don_t_Stop_Til_You_Get_Enough_Official_VideoMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Hollywood_Tonight_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Man_In_The_Mirror_Live_at_the_30th_Annual_Grammy_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Man_In_The_Mirror_Official_VideoMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Remember_The_Time_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Smooth_Criminal_Official_Video_Shortened_VersionMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_s_Drummer_Jonathan_Moffett_Performs_Thriller_MP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_They_Don_t_Care_About_Us_Brazil_Version_Official_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_The_Way_You_Make_Me_Feel_Official_VideoMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_The_Way_You_Make_Me_Feel_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_We_Are_Here_To_Change_The_World_Another_Part_Of_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_Will_You_Be_There_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_You_Are_Not_Alone_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Michael_Jackson_You_Rock_My_World_Official_VideoMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Scared of the moon - Michael jackson(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "You Rock My World(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "_RoneyBoys_Ian_and_Isaac_sing_Michael_Jackson_Rockin_RobinMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "128-Jana Gana Mana Adhinayak Jay He - Hamrahi 128 Kbps_mfcc.csv\n",
      "(20, 25000)\n",
      "1st_song_lata_Aasha_Jana_Gana_Mana_Lata_Mangeshkar_Asha_BhosleMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Alia_Bhatt_Sang_National_Anthem_at_pro_kabddi_leagueMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Amitabh_Bachchan_Singing_National_Anthem_At_Eden_GardenMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "INDIAN National anthem in shreya ghoshal voice(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Indian_National_Anthem_in_the_voice_of_A_R_Rahman_Jana_Gana_ManaMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "INDIAN_NATIONAL_ANTHEM_JANA_GANA_MANA_KARAOKE_TRACKMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Indian_National_Anthem_Jana_Gana_Mana_Vocals_and_LyricsMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "INDIA_National_Anthem_Sung_by_Refugees_from_different_countries_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana - Major 320 Kbps_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana - The Virtual National Anthem(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana All Vocals(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana By Sonu Nigam_ Bickram Ghosh(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana gana mana singing other countries girl(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana _ 52 SECONDS _ ZEAL INSTITUTES(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana _ National Anthem by Children(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "JANA GANA MANA _ National Anthem _ 2017(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana Gana Mana_320(PagalWorld.com.sb)_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Adhinayak_by_Kids_Jan_Gan_Man_National_Anthem_Song_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Adhinayak_II_National_Anthem_II_arshasveerakavlogMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_HD_National_Anthem_With_Lyrics_Best_Patriotic_SongMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Indian_National_Anthem_with_Vir_the_Robot_Boy_WowKidz_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Kabhi_Khushi_Kabhie_Gham_2001_Full_Song_German_SubMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Lata_Mangeshkar_National_Anthem_Jana_Gana_Mana_Jana_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_National_Anthem_India_Cutest_Kid​_Independence_Day_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_National_Anthem_Of_India_Namita_Agrawal_22_Top_Participants_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_National_Anthem_जन_गण_मन_राष्ट्रगानMP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Parineeti_Chopra_Independence_DayMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Republic_Day_Wishes_SN_ProductionsMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_Shreya_Karmakar_Independence_Day_2019_National_AnthemMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_Mana_The_Soul_Of_India_Kaushiki_ChakrabortyMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "Jana_Gana_mana_wift_India_national_anthem_Dance_Choreography_Boy_mfcc.csv\n",
      "(20, 25000)\n",
      "JANA_GANA_MANA_🇮🇳_Indian_National_Anthem_LYRICAL_🇮🇳Independence (2)_mfcc.csv\n",
      "(20, 25000)\n",
      "JANA_GANA_MANA_🇮🇳_Indian_National_Anthem_LYRICAL_🇮🇳Independence_mfcc.csv\n",
      "(20, 25000)\n",
      "Jan_Gan_Man_Adhinayak_Jay_He_जन_गण_मन_अधिनायक_जय_हे_भारत_भाग्य_विधाताMP3_mfcc.csv\n",
      "(20, 25000)\n",
      "Jan_Gan_Man_by_Kid_Happy_Independence_Day_Song_Jana_Gana_Mana_Adhinayak_mfcc.csv\n",
      "(20, 25000)\n",
      "National Anthem - Tribute To Women In Police Force(MP3_128K) (2)_mfcc.csv\n",
      "(20, 25000)\n",
      "National Anthem - Tribute To Women In Police Force(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "National Anthem By Shreya Ghoshal - Jana Gana Mana(MP3_128K)_mfcc.csv\n",
      "(20, 25000)\n",
      "National Anthem By Shreya Ghoshal - Jana Gana Mana(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "National Anthem in the voice of Amitabh Bachchan(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "National_Anthem_52_Second_भारतीय_राष्ट्रीय_गानMP3_160K_mfcc.csv\n",
      "(20, 25000)\n",
      "National_Anthem_by_Hrithik_Roshan_Jana_Gana_Mana_Jai_Hind_Pro_Kabaddi_mfcc.csv\n",
      "(20, 25000)\n",
      "rabindranath tagore singing jana gana mana(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Shruthi haasan Sings the Proud Song of INDIA(MP3_160K)_mfcc.csv\n",
      "(20, 25000)\n",
      "Sidharth_Malhotra_Singing_NATIONAL_ANTHEM_of_INDIA_HAPPY_74th_INDEPENDENCE_mfcc.csv\n",
      "(20, 25000)\n",
      "Sunny_Leone_singing_National_Anthem_at_Pro_Kabaddi_2016MP3_128K_mfcc.csv\n",
      "(20, 25000)\n",
      "Tulsi_Kumar_singing_National_Anthem_at_VivoProKabaddiLeague2019MP3_mfcc.csv\n",
      "(20, 25000)\n",
      "जन_गण_मन_I_Jan_Gan_Man_I_MAHENDRA_KAPOOR_I_राष्ट्र_गान_राष्ट्र_mfcc.csv\n",
      "(20, 25000)\n",
      "Asha Bhosle: 50 files\n",
      "Bhavgeet: 50 files\n",
      "Kishor Kumar: 50 files\n",
      "Lavni: 52 files\n",
      "Michael Jackson: 50 files\n",
      "National Anthem: 49 files\n"
     ]
    }
   ],
   "source": [
    "def load_mfcc_files(directory):\n",
    "    mfcc_data = []\n",
    "    for file in os.listdir(directory):\n",
    "            print(file)\n",
    "            file_path = os.path.join(directory, file)\n",
    "            data = pd.read_csv(file_path, header=None).values\n",
    "            mfcc_data.append(data)\n",
    "            print(data.shape)\n",
    "    return mfcc_data\n",
    "\n",
    "# Load MFCC data\n",
    "asha = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\Asha Bhosle\")\n",
    "bhavgeet = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\Bhavgeet\")\n",
    "kishor = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\Kishor Kumar\")\n",
    "lavni = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\Lavni\")\n",
    "michael = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\Michael Jackson\")\n",
    "national = load_mfcc_files(\"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_train_proccessed\\\\National Anthem\")\n",
    "\n",
    "# Debug: Print the number of files loaded from each directory\n",
    "print(f\"Asha Bhosle: {len(asha)} files\")\n",
    "print(f\"Bhavgeet: {len(bhavgeet)} files\")\n",
    "print(f\"Kishor Kumar: {len(kishor)} files\")\n",
    "print(f\"Lavni: {len(lavni)} files\")\n",
    "print(f\"Michael Jackson: {len(michael)} files\")\n",
    "print(f\"National Anthem: {len(national)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINING DATA INTO A SINGLE NUMPY ARRAY WITH LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20, 25000)\n",
      "(50, 20, 25000)\n",
      "(50, 20, 25000)\n",
      "(52, 20, 25000)\n",
      "(50, 20, 25000)\n",
      "(49, 20, 25000)\n",
      "new\n",
      "(49, 20, 25000)\n",
      "(49, 20, 25000)\n",
      "(49, 20, 25000)\n",
      "(49, 20, 25000)\n",
      "(49, 20, 25000)\n",
      "(49, 20, 25000)\n"
     ]
    }
   ],
   "source": [
    "#repeat songs\n",
    "\n",
    "asha = np.array(asha)\n",
    "bhavgeet = np.array(bhavgeet)\n",
    "kishor=np.array(kishor)\n",
    "lavni=np.array(lavni)\n",
    "michael=np.array(michael)\n",
    "national=np.array(national)\n",
    "print(asha.shape)\n",
    "print(bhavgeet.shape)\n",
    "print(kishor.shape)\n",
    "print(lavni.shape)\n",
    "print(michael.shape)\n",
    "print(national.shape)\n",
    "\n",
    "asha=asha[:-1]\n",
    "bhavgeet = bhavgeet[:-1]\n",
    "kishor=kishor[:-1]\n",
    "lavni=lavni[:-3]\n",
    "\n",
    "michael=michael[:-1]\n",
    "print(\"new\")\n",
    "print(asha.shape)\n",
    "print(bhavgeet.shape)\n",
    "print(kishor.shape)\n",
    "print(lavni.shape)\n",
    "print(michael.shape)\n",
    "print(national.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (294, 20, 25001)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine data\n",
    "data = np.concatenate((asha, bhavgeet, kishor, lavni, michael, national), axis=0)\n",
    "\n",
    "# Create labels\n",
    "labels = ['asha'] * len(asha) + ['bhavgeet'] * len(bhavgeet) + ['kishor'] * len(kishor) + ['lavni'] * len(lavni) + ['michael'] * len(michael) + ['national'] * len(national)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Combine data and labels into a single array\n",
    "combined_data = np.empty((data.shape[0], data.shape[1], data.shape[2] + 1), dtype=object)\n",
    "combined_data[:, :, :-1] = data\n",
    "combined_data[:, 0, -1] = encoded_labels  # Add labels in the last column\n",
    "\n",
    "# Check the shape of the combined data\n",
    "print(f\"Combined data shape: {combined_data.shape}\")\n",
    "\n",
    "#The shape of combined_data will be (294, 20, 25001), where the last element in the innermost dimension contains the encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (294, 20, 25000)\n",
      "y shape: (294,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Extract the data without the labels\n",
    "X = combined_data[:, :, :-1]\n",
    "\n",
    "# Extract the labels\n",
    "y = combined_data[:, 0, -1]\n",
    "\n",
    "# Print the shapes of X and y to verify\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int32)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print the encoded labels to verify\n",
    "print(f\"Encoded labels: {encoded_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITING TRAIN SET INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Apply target encoding\u001b[39;00m\n\u001b[0;32m     17\u001b[0m target_encoder \u001b[38;5;241m=\u001b[39m TargetEncoder()\n\u001b[1;32m---> 18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Extract the data without the labels\u001b[39;00m\n\u001b[0;32m     21\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_label\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\category_encoders\\utils.py:474\u001b[0m, in \u001b[0;36mSupervisedTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_transform() missing argument: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\category_encoders\\utils.py:320\u001b[0m, in \u001b[0;36mBaseEncoder.fit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns to be encoded can not contain null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# for finding invariant columns transform without y (as is done on the test set)\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_out_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Issue#437\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\category_encoders\\target_encoder.py:187\u001b[0m, in \u001b[0;36mTargetEncoder._fit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_target_encoding(pd\u001b[38;5;241m.\u001b[39mconcat([X_ordinal, X_hier_ordinal], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_target_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ordinal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\category_encoders\\target_encoder.py:212\u001b[0m, in \u001b[0;36mTargetEncoder.fit_target_encoding\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    209\u001b[0m             scalar_hier_long\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, scalar_hier_long\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    210\u001b[0m             scalar \u001b[38;5;241m=\u001b[39m scalar_hier_long[col_hier]\u001b[38;5;241m.\u001b[39mmap(scalar_hier\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m--> 212\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m(X[col])\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    213\u001b[0m smoove \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weighting(stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    215\u001b[0m smoothing \u001b[38;5;241m=\u001b[39m scalar \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m smoove) \u001b[38;5;241m+\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m smoove\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine data\n",
    "data = np.concatenate((asha, bhavgeet, kishor, lavni, michael, national), axis=0)\n",
    "\n",
    "# Create labels\n",
    "labels = ['asha'] * len(asha) + ['bhavgeet'] * len(bhavgeet) + ['kishor'] * len(kishor) + ['lavni'] * len(lavni) + ['michael'] * len(michael) + ['national'] * len(national)\n",
    "\n",
    "# Convert data and labels to a DataFrame\n",
    "df = pd.DataFrame(data.reshape(data.shape[0], -1))\n",
    "df['label'] = labels\n",
    "\n",
    "# Apply target encoding\n",
    "target_encoder = TargetEncoder()\n",
    "df['encoded_label'] = target_encoder.fit_transform(df[['label']], df['label'])\n",
    "\n",
    "# Extract the data without the labels\n",
    "X = df.drop(columns=['label', 'encoded_label']).values\n",
    "y = df['encoded_label'].values\n",
    "\n",
    "# Print the shapes of X and y to verify\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "\n",
    "# Reshape the training and testing data back to the original shape\n",
    "x_train = x_train.reshape(-1, data.shape[1], data.shape[2])\n",
    "x_test = x_test.reshape(-1, data.shape[1], data.shape[2])\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 20, 25000)\n",
      "(59, 20, 25000)\n",
      "(59, 20, 25000)\n",
      "[[[-469.76727 -469.76727 -469.76727 ...    0.         0.         0.     ]\n",
      "  [   0.         0.         0.      ...    0.         0.         0.     ]\n",
      "  [   0.         0.         0.      ...    0.         0.         0.     ]\n",
      "  ...\n",
      "  [   0.         0.         0.      ...    0.         0.         0.     ]\n",
      "  [   0.         0.         0.      ...    0.         0.         0.     ]\n",
      "  [   0.         0.         0.      ...    0.         0.         0.     ]]]\n",
      "(1, 20, 25000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Split the dataset into training and test sets (80% training, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, encoded_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split the training set into training and validation sets (80% training, 20% validation)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(x_val[:1])\n",
    "print(x_val[:1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model trying multiple classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE MODEL WHICH WORKS WELL!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.1591 - loss: 2.6277 - val_accuracy: 0.2034 - val_loss: 4.3961 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.3087 - loss: 2.0032 - val_accuracy: 0.2712 - val_loss: 3.7133 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4282 - loss: 1.8393 - val_accuracy: 0.2034 - val_loss: 3.0448 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.4688 - loss: 1.5289 - val_accuracy: 0.2034 - val_loss: 3.4948 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4736 - loss: 1.3493 - val_accuracy: 0.2034 - val_loss: 3.9553 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4388 - loss: 1.6506 - val_accuracy: 0.2203 - val_loss: 3.3495 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.5712 - loss: 1.2846 - val_accuracy: 0.2712 - val_loss: 2.5677 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5876 - loss: 1.2140 - val_accuracy: 0.3898 - val_loss: 2.2148 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5122 - loss: 1.4058 - val_accuracy: 0.4915 - val_loss: 1.8112 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6093 - loss: 1.1972 - val_accuracy: 0.4407 - val_loss: 1.6043 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5940 - loss: 1.2509 - val_accuracy: 0.5424 - val_loss: 1.3119 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5742 - loss: 1.1095 - val_accuracy: 0.5424 - val_loss: 1.2062 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5640 - loss: 1.3034 - val_accuracy: 0.5085 - val_loss: 1.2053 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5560 - loss: 1.3627 - val_accuracy: 0.4746 - val_loss: 1.1023 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6736 - loss: 1.1538 - val_accuracy: 0.6441 - val_loss: 0.9997 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5780 - loss: 1.1963 - val_accuracy: 0.7119 - val_loss: 0.9457 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.6529 - loss: 1.0104 - val_accuracy: 0.7119 - val_loss: 0.9736 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6234 - loss: 0.9216 - val_accuracy: 0.6610 - val_loss: 0.9957 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7068 - loss: 0.8287 - val_accuracy: 0.6780 - val_loss: 1.0224 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6269 - loss: 0.9043 - val_accuracy: 0.6780 - val_loss: 1.0023 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6842 - loss: 0.7860 - val_accuracy: 0.6949 - val_loss: 0.9319 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7407 - loss: 0.7257 - val_accuracy: 0.7119 - val_loss: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7885 - loss: 0.6027 - val_accuracy: 0.6441 - val_loss: 1.0154 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7742 - loss: 0.6735 - val_accuracy: 0.6610 - val_loss: 0.9908 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7615 - loss: 0.8095 - val_accuracy: 0.6780 - val_loss: 0.9291 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7780 - loss: 0.6545 - val_accuracy: 0.6780 - val_loss: 0.9589 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7710 - loss: 0.6790 - val_accuracy: 0.7119 - val_loss: 0.9732 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8041 - loss: 0.5448 - val_accuracy: 0.6610 - val_loss: 1.0470 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8039 - loss: 0.5145 - val_accuracy: 0.6780 - val_loss: 0.9820 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8202 - loss: 0.4699 - val_accuracy: 0.6610 - val_loss: 1.0686 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9413 - loss: 0.2787 - val_accuracy: 0.6610 - val_loss: 1.0776 - learning_rate: 5.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8994 - loss: 0.3726 - val_accuracy: 0.6441 - val_loss: 1.0159 - learning_rate: 5.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9305 - loss: 0.2570 - val_accuracy: 0.6610 - val_loss: 0.9923 - learning_rate: 5.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9076 - loss: 0.2753 - val_accuracy: 0.6441 - val_loss: 1.0247 - learning_rate: 5.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9016 - loss: 0.3203 - val_accuracy: 0.6441 - val_loss: 1.0451 - learning_rate: 5.0000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7689 - loss: 0.9543 \n",
      "Test accuracy: 0.7627118825912476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │     \u001b[38;5;34m4,000,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_42 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_43 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,312,692</span> (46.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,312,692\u001b[0m (46.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,104,038</span> (15.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,104,038\u001b[0m (15.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,208,078</span> (31.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m8,208,078\u001b[0m (31.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Accuracy: 0.7627118644067796\n",
      "Precision: 0.7802585832246849\n",
      "Recall: 0.7627118644067796\n",
      "F1 Score: 0.7621434685841465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        11\n",
      "           1       1.00      0.64      0.78        11\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.38      0.43      0.40         7\n",
      "           4       0.62      0.62      0.62         8\n",
      "           5       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.75      0.74      0.73        59\n",
      "weighted avg       0.78      0.76      0.76        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming x_train, x_val, x_test, y_train, y_val, y_test are already defined\n",
    "# and have the shape (176, 20, 25000)\n",
    "\n",
    "# Build the CNN model for feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 5, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(2, padding='same'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    \n",
    "\n",
    "    #model.add(layers.Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.MaxPooling1D(2, padding='same'))\n",
    "    #model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Conv1D(128, 5, activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(2, padding='same'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(6, activation='softmax'))  # Assuming 6 classes for classification\n",
    "    return model\n",
    "\n",
    "input_shape = (20, 25000)  # Adjusted to match the input data shape\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape the data to match the input shape of the model\n",
    "x_train = x_train.reshape(-1, 20, 25000)\n",
    "x_val = x_val.reshape(-1, 20, 25000)\n",
    "x_test = x_test.reshape(-1, 20, 25000)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "# Train the CNN model with early stopping\n",
    "cnn_model.fit(x_train, y_train, epochs=200, batch_size=16, validation_data=(x_val, y_val), callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "\n",
    "# Assuming X_test and y_test are your test data and labels\n",
    "X_test = x_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)  # Ensure y_test is integer type for sparse_categorical_crossentropy\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "cnn_model.summary()\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels if necessary\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the RBMLayer (assuming you have this implemented)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRBMLayer\u001b[39;00m(\u001b[43mlayers\u001b[49m\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_components):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(RBMLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the RBMLayer (assuming you have this implemented)\n",
    "class RBMLayer(layers.Layer):\n",
    "    def __init__(self, n_components):\n",
    "        super(RBMLayer, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        # Add your RBM layer initialization here\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Add your RBM layer logic here\n",
    "        return inputs\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    # Conv1D Layer: 64 filters, filter size of 5, stride of 1\n",
    "    model.add(layers.Conv1D(64, 5, activation='relu', strides=1, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling Layer: Pool size of 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # RBM Layer 1: 100 hidden units\n",
    "    rbm_layer1 = RBMLayer(n_components=100)\n",
    "    model.add(rbm_layer1)\n",
    "    \n",
    "    # RBM Layer 2: 50 hidden units\n",
    "    rbm_layer2 = RBMLayer(n_components=50)\n",
    "    model.add(rbm_layer2)\n",
    "    \n",
    "    # Add a dense layer for classification\n",
    "    model.add(layers.Dense(6, activation='softmax'))  # Assuming 10 classes for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (20, 25000)  # Example input shape\n",
    "rbm_model = build_model(input_shape)\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "rbm_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Assuming you have your training data in X_train and y_train\n",
    "# And your validation data in X_val and y_val\n",
    "history = rbm_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "print(\"\\nModel layers after initialization:\")\n",
    "for idx, layer in enumerate(rbm_model.layers):\n",
    "    print(f\"Layer {idx}: {layer.name}\")\n",
    "# Run a single prediction to initialize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,000,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m8,000,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_39 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_33 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_56 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_57 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,016,096</span> (91.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,016,096\u001b[0m (91.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,005,322</span> (30.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,005,322\u001b[0m (30.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,010,646</span> (61.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,010,646\u001b[0m (61.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_33 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_54\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Create a new model that outputs the desired layer\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Prepare your input data\u001b[39;00m\n\u001b[0;32m     16\u001b[0m input_data \u001b[38;5;241m=\u001b[39m x_val[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Your input data here\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_33 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load your custom model\n",
    "model = rbm_model\n",
    "\n",
    "# Print the model summary to identify the layer names\n",
    "model.summary()\n",
    "\n",
    "# Choose the layer from which you want to extract features\n",
    "layer_name = 'rbm_layer_57'\n",
    "\n",
    "# Create a new model that outputs the desired layer\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "# Prepare your input data\n",
    "input_data = x_val[:1] # Your input data here\n",
    "\n",
    "# Extract features\n",
    "features = feature_extractor.predict(input_data)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_33 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage with the correct layer name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbm_layer_57\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual name of the RBM layer\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrbm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m X_test_features \u001b[38;5;241m=\u001b[39m extract_features(rbm_model, layer_name, x_test)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print the shape of the extracted features\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[80], line 18\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, layer_name, input_data)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mExtract features from a specific layer of the model.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mnumpy.ndarray: The extracted features.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_layer(name\u001b[38;5;241m=\u001b[39mlayer_name)\n\u001b[1;32m---> 18\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     19\u001b[0m features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(input_data)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_33 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "# Ensure the model has been called with input data\n",
    "rbm_model.predict(x_train[:1])  # Run a prediction with a single sample\n",
    "\n",
    "# Define the function to extract features\n",
    "def extract_features(model, layer_name, input_data):\n",
    "    \"\"\"\n",
    "    Extract features from a specific layer of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the layer to extract features from.\n",
    "    input_data (numpy.ndarray): The input data.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The extracted features.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    feature_extractor = models.Model(inputs=model.input, outputs=layer.output)\n",
    "    features = feature_extractor.predict(input_data)\n",
    "    return features\n",
    "\n",
    "# Example usage with the correct layer name\n",
    "layer_name = 'rbm_layer_57'  # Replace with the actual name of the RBM layer\n",
    "X_train_features = extract_features(rbm_model, layer_name, x_train)\n",
    "X_test_features = extract_features(rbm_model, layer_name, x_test)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(\"X_train_features shape:\", X_train_features.shape)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(\"X_train_features shape:\", X_train_features.shape)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "\n",
    "# Now you can use the extracted features for further processing, e.g., training a RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForestClassifier on the extracted features\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test features\n",
    "test_accuracy = clf.score(X_test_features, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_32 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m rbm_model\u001b[38;5;241m.\u001b[39mpredict(x_val[:\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Extract features from the RBM model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mrbm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mrbm_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m      5\u001b[0m x_train_features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[0;32m      6\u001b[0m x_val_features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(x_val)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_32 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "rbm_model.predict(x_val[:1])\n",
    "\n",
    "# Extract features from the RBM model\n",
    "feature_extractor = models.Model(inputs=rbm_model.input, outputs=rbm_model.layers[-2].output)\n",
    "x_train_features = feature_extractor.predict(x_train)\n",
    "x_val_features = feature_extractor.predict(x_val)\n",
    "x_test_features = feature_extractor.predict(x_test)\n",
    "\n",
    "# Train additional classifiers\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "lr.fit(x_train_features, y_train)\n",
    "rf.fit(x_train_features, y_train)\n",
    "svc.fit(x_train_features, y_train)\n",
    "# Combine the classifiers using VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('rf', rf),\n",
    "    ('svc', svc)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Evaluate the ensemble model on the test data\n",
    "y_pred = ensemble_model.predict(x_test_features)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary before prediction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,000,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m8,000,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_38 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_32 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_54 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_55 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,016,096</span> (91.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,016,096\u001b[0m (91.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,005,322</span> (30.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,005,322\u001b[0m (30.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,010,646</span> (61.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,010,646\u001b[0m (61.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model with first sample...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Model layers after initialization:\n",
      "Layer 0: conv1d_38\n",
      "Layer 1: batch_normalization_21\n",
      "Layer 2: max_pooling1d_38\n",
      "Layer 3: dropout_44\n",
      "Layer 4: flatten_32\n",
      "Layer 5: rbm_layer_54\n",
      "Layer 6: rbm_layer_55\n",
      "Layer 7: dense_53\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_32 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Now create the feature extractor\u001b[39;00m\n\u001b[0;32m     15\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m---> 16\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m\u001b[43mrbm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m,\n\u001b[0;32m     17\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mrbm_model\u001b[38;5;241m.\u001b[39mget_layer(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39moutput  \u001b[38;5;66;03m# Get second-to-last layer explicitly\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracting features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_32 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "# First, verify the model is properly initialized\n",
    "print(\"Model summary before prediction:\")\n",
    "rbm_model.summary()\n",
    "\n",
    "# Initialize the model with a single sample\n",
    "print(\"\\nInitializing model with first sample...\")\n",
    "initial_prediction = rbm_model.predict(x_val[:1])\n",
    "\n",
    "# Verify the model layers\n",
    "print(\"\\nModel layers after initialization:\")\n",
    "for idx, layer in enumerate(rbm_model.layers):\n",
    "    print(f\"Layer {idx}: {layer.name}\")\n",
    "\n",
    "# Now create the feature extractor\n",
    "feature_extractor = models.Model(\n",
    "    inputs=rbm_model.input,\n",
    "    outputs=rbm_model.get_layer(index=-2).output  # Get second-to-last layer explicitly\n",
    ")\n",
    "\n",
    "# Extract features\n",
    "print(\"\\nExtracting features...\")\n",
    "x_train_features = feature_extractor.predict(x_train)\n",
    "x_val_features = feature_extractor.predict(x_val)\n",
    "x_test_features = feature_extractor.predict(x_test)\n",
    "\n",
    "# Continue with the ensemble model\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "print(\"\\nTraining classifiers...\")\n",
    "lr.fit(x_train_features, y_train)\n",
    "rf.fit(x_train_features, y_train)\n",
    "svc.fit(x_train_features, y_train)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('rf', rf),\n",
    "    ('svc', svc)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with rbm which works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "x_train shape: (176, 20, 25000)\n",
      "y_train shape: (176,)\n",
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.1935 - loss: 4.0846 - val_accuracy: 0.2034 - val_loss: 3.3268 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.1296 - loss: 3.2671 - val_accuracy: 0.1356 - val_loss: 2.9455 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.0975 - loss: 2.8932 - val_accuracy: 0.2034 - val_loss: 2.7211 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.1759 - loss: 2.7019 - val_accuracy: 0.1356 - val_loss: 2.5920 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.1723 - loss: 2.5257 - val_accuracy: 0.2034 - val_loss: 2.4384 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1003 - loss: 2.4322 - val_accuracy: 0.1356 - val_loss: 2.4002 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1410 - loss: 2.3798 - val_accuracy: 0.1356 - val_loss: 2.3355 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.2101 - loss: 2.3036 - val_accuracy: 0.1356 - val_loss: 2.2944 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.1355 - loss: 2.2987 - val_accuracy: 0.1864 - val_loss: 2.2211 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.2041 - loss: 2.2358 - val_accuracy: 0.1356 - val_loss: 2.2687 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1075 - loss: 2.2457 - val_accuracy: 0.2034 - val_loss: 2.1708 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1435 - loss: 2.1890 - val_accuracy: 0.1356 - val_loss: 2.1932 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.1727 - loss: 2.1827 - val_accuracy: 0.1356 - val_loss: 2.2050 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1471 - loss: 2.1553 - val_accuracy: 0.2034 - val_loss: 2.1452 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.1845 - loss: 2.1393 - val_accuracy: 0.1356 - val_loss: 2.1385 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1596 - loss: 2.1403 - val_accuracy: 0.1356 - val_loss: 2.1679 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.1316 - loss: 2.1409 - val_accuracy: 0.2034 - val_loss: 2.1140 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.1874 - loss: 2.1101 - val_accuracy: 0.1356 - val_loss: 2.1037 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1760 - loss: 2.1166 - val_accuracy: 0.1356 - val_loss: 2.1349 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2098 - loss: 2.0919 - val_accuracy: 0.2034 - val_loss: 2.0856 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.2150 - loss: 2.0851 - val_accuracy: 0.1356 - val_loss: 2.0899 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1962 - loss: 2.1002 - val_accuracy: 0.1356 - val_loss: 2.1033 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1630 - loss: 2.0801 - val_accuracy: 0.2034 - val_loss: 2.0752 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1609 - loss: 2.0853 - val_accuracy: 0.1356 - val_loss: 2.0847 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2127 - loss: 2.0479 - val_accuracy: 0.1864 - val_loss: 2.0538 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1578 - loss: 2.0493 - val_accuracy: 0.1356 - val_loss: 2.0455 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1923 - loss: 2.0451 - val_accuracy: 0.1356 - val_loss: 2.0574 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1625 - loss: 2.0476 - val_accuracy: 0.1864 - val_loss: 2.0318 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.1097 - loss: 2.0550 - val_accuracy: 0.1356 - val_loss: 2.0362 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1225 - loss: 2.0355 - val_accuracy: 0.1356 - val_loss: 2.0444 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1655 - loss: 2.0312 - val_accuracy: 0.1356 - val_loss: 2.0239 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1147 - loss: 2.0248 - val_accuracy: 0.1356 - val_loss: 2.0196 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.1575 - loss: 2.0165 - val_accuracy: 0.1356 - val_loss: 2.0178 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.1734 - loss: 2.0018 - val_accuracy: 0.1356 - val_loss: 2.0268 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.1741 - loss: 2.0099 - val_accuracy: 0.1356 - val_loss: 2.0054 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1687 - loss: 2.0041 - val_accuracy: 0.1356 - val_loss: 2.0097 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1884 - loss: 1.9863 - val_accuracy: 0.2034 - val_loss: 1.9800 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1744 - loss: 1.9795 - val_accuracy: 0.1356 - val_loss: 1.9812 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1740 - loss: 1.9908 - val_accuracy: 0.1356 - val_loss: 1.9920 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.2069 - loss: 1.9791 - val_accuracy: 0.2034 - val_loss: 1.9778 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1056 - loss: 1.9766 - val_accuracy: 0.1356 - val_loss: 1.9710 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2036 - loss: 1.9625 - val_accuracy: 0.1356 - val_loss: 1.9701 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1856 - loss: 1.9607 - val_accuracy: 0.1356 - val_loss: 1.9592 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1560 - loss: 1.9545 - val_accuracy: 0.2034 - val_loss: 1.9604 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1434 - loss: 1.9601 - val_accuracy: 0.1356 - val_loss: 1.9613 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1024 - loss: 1.9641 - val_accuracy: 0.1356 - val_loss: 1.9348 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1650 - loss: 1.9402 - val_accuracy: 0.1356 - val_loss: 1.9552 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1686 - loss: 1.9388 - val_accuracy: 0.1356 - val_loss: 1.9667 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1751 - loss: 1.9394 - val_accuracy: 0.1356 - val_loss: 1.9400 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.0945 - loss: 1.9527 - val_accuracy: 0.1356 - val_loss: 1.9217 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.1768 - loss: 1.9279 - val_accuracy: 0.1356 - val_loss: 1.9448 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1753 - loss: 1.9169 - val_accuracy: 0.1356 - val_loss: 1.9326 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1904 - loss: 1.9228 - val_accuracy: 0.1864 - val_loss: 1.9174 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1578 - loss: 1.9192 - val_accuracy: 0.1356 - val_loss: 1.9278 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.1148 - loss: 1.9216 - val_accuracy: 0.1356 - val_loss: 1.9158 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1478 - loss: 1.9087 - val_accuracy: 0.1356 - val_loss: 1.9154 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1573 - loss: 1.9159 - val_accuracy: 0.1356 - val_loss: 1.9113 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.1861 - loss: 1.9064 - val_accuracy: 0.1356 - val_loss: 1.9249 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.2143 - loss: 1.8897 - val_accuracy: 0.1356 - val_loss: 1.9139 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.1987 - loss: 1.8989 - val_accuracy: 0.2034 - val_loss: 1.8851 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.1348 - loss: 1.9005 - val_accuracy: 0.1356 - val_loss: 1.9068 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.1644 - loss: 1.8918 - val_accuracy: 0.2034 - val_loss: 1.9052 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1474 - loss: 1.9012 - val_accuracy: 0.1356 - val_loss: 1.8914 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1289 - loss: 1.8944 - val_accuracy: 0.1356 - val_loss: 1.9169 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.1827 - loss: 1.8835 - val_accuracy: 0.1356 - val_loss: 1.8870 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.1477 - loss: 1.8917 - val_accuracy: 0.1356 - val_loss: 1.8887 - learning_rate: 2.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.2084 - loss: 1.8822 - val_accuracy: 0.1356 - val_loss: 1.8905 - learning_rate: 2.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.2171 - loss: 1.8774 - val_accuracy: 0.1356 - val_loss: 1.8917 - learning_rate: 2.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.1900 - loss: 1.8797 - val_accuracy: 0.1356 - val_loss: 1.8901 - learning_rate: 2.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1681 - loss: 1.8769 - val_accuracy: 0.1356 - val_loss: 1.8904 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the RBMLayer\n",
    "class RBMLayer(layers.Layer):\n",
    "    def __init__(self, n_components, learning_rate=0.01, k=10, **kwargs):\n",
    "        super(RBMLayer, self).__init__(**kwargs)\n",
    "        self.n_components = n_components\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k = k  # Number of Gibbs sampling steps\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], self.n_components),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.h_bias = self.add_weight(shape=(self.n_components,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.v_bias = self.add_weight(shape=(input_shape[-1],),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Positive phase\n",
    "        h_prob = tf.nn.sigmoid(tf.matmul(inputs, self.W) + self.h_bias)\n",
    "        h_state = tf.nn.relu(tf.sign(h_prob - tf.random.uniform(tf.shape(h_prob))))\n",
    "\n",
    "        # Gibbs sampling\n",
    "        for _ in range(self.k):\n",
    "            v_prob = tf.nn.sigmoid(tf.matmul(h_state, tf.transpose(self.W)) + self.v_bias)\n",
    "            v_state = tf.nn.relu(tf.sign(v_prob - tf.random.uniform(tf.shape(v_prob))))\n",
    "            h_prob = tf.nn.sigmoid(tf.matmul(v_state, self.W) + self.h_bias)\n",
    "            h_state = tf.nn.relu(tf.sign(h_prob - tf.random.uniform(tf.shape(h_prob))))\n",
    "\n",
    "        # Negative phase\n",
    "        v_prob = tf.nn.sigmoid(tf.matmul(h_state, tf.transpose(self.W)) + self.v_bias)\n",
    "\n",
    "        # Update weights\n",
    "        positive_grad = tf.matmul(tf.transpose(inputs), h_prob)\n",
    "        negative_grad = tf.matmul(tf.transpose(v_prob), h_prob)\n",
    "\n",
    "        self.W.assign_add(self.learning_rate * (positive_grad - negative_grad))\n",
    "        self.v_bias.assign_add(self.learning_rate * tf.reduce_mean(inputs - v_prob, axis=0))\n",
    "        self.h_bias.assign_add(self.learning_rate * tf.reduce_mean(h_prob - h_state, axis=0))\n",
    "\n",
    "        return h_prob\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(layers.Conv1D(128, 3, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    rbm_layer1 = RBMLayer(n_components=100)\n",
    "    model.add(rbm_layer1)\n",
    "    \n",
    "    rbm_layer2 = RBMLayer(n_components=50)\n",
    "    model.add(rbm_layer2)\n",
    "    rbm_layer3 = RBMLayer(n_components=50)\n",
    "    model.add(rbm_layer3)\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(layers.Dense(6, activation='softmax'))  # Assuming 6 classes for classification\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (20, 25000)  # Adjusted to match the input data shape\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Ensure x_train and y_train are NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Check the shapes of x_train and y_train\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model testing and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.1425 - loss: 1.8959 \n",
      "Test accuracy: 0.1355932205915451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_52\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_52\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,884</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_70 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m4,800,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_70 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_71 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_71 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_50 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_90 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m38,884\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_91 (\u001b[38;5;33mRBMLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m13,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,650,202</span> (55.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,650,202\u001b[0m (55.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,883,400</span> (18.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,883,400\u001b[0m (18.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,766,802</span> (37.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,766,802\u001b[0m (37.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "Accuracy: 0.13559322033898305\n",
      "Precision: 0.018385521401896008\n",
      "Recall: 0.13559322033898305\n",
      "F1 Score: 0.03238047052871237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.14      1.00      0.24         8\n",
      "           5       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.14        59\n",
      "   macro avg       0.02      0.17      0.04        59\n",
      "weighted avg       0.02      0.14      0.03        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming X_test and y_test are your test data and labels\n",
    "X_test = x_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)  # Ensure y_test is integer type for sparse_categorical_crossentropy\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have your test data in X_test and y_test\n",
    "# And your trained model is named 'model'\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels if necessary\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_6 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     20\u001b[0m layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_12\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the name of the layer you want to extract features from\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m X_test_features \u001b[38;5;241m=\u001b[39m extract_features(model, layer_name, X_test)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Print the shape of the extracted features\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, layer_name, input_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mExtract features from a specific layer of the model.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mnumpy.ndarray: The extracted features.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_layer(name\u001b[38;5;241m=\u001b[39mlayer_name)\n\u001b[1;32m---> 15\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     16\u001b[0m features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(input_data)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_6 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "# Define the function to extract features\n",
    "def extract_features(model, layer_name, input_data):\n",
    "    \"\"\"\n",
    "    Extract features from a specific layer of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the layer to extract features from.\n",
    "    input_data (numpy.ndarray): The input data.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The extracted features.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    feature_extractor = models.Model(inputs=model.input, outputs=layer.output)\n",
    "    features = feature_extractor.predict(input_data)\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "layer_name = 'dense_12'  # Replace with the name of the layer you want to extract features from\n",
    "X_train_features = extract_features(model, layer_name, x_train)\n",
    "X_test_features = extract_features(model, layer_name, X_test)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(\"X_train_features shape:\", X_train_features.shape)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "\n",
    "# Now you can use the extracted features for further processing, e.g., training a RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForestClassifier on the extracted features\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test features\n",
    "test_accuracy = clf.score(X_test_features, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to visualize what cdbn is doing (subject to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, layer_name, input_data):\n",
    "    \"\"\"\n",
    "    Visualize the feature maps of a convolutional layer.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the convolutional layer.\n",
    "    input_data (numpy.ndarray): The input data.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    feature_map_model = models.Model(inputs=model.input, outputs=layer.output)\n",
    "    feature_maps = feature_map_model.predict(input_data)\n",
    "    \n",
    "    n_features = feature_maps.shape[-1]\n",
    "    fig, axes = plt.subplots(1, n_features, figsize=(20, 5))\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        axes[i].imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def visualize_filters(model, layer_name):\n",
    "    \"\"\"\n",
    "    Visualize the filters of a convolutional layer.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the convolutional layer.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    filters, biases = layer.get_weights()\n",
    "    \n",
    "    # Normalize filter values to 0-1 so we can visualize them\n",
    "    f_min, f_max = filters.min(), filters.max()\n",
    "    filters = (filters - f_min) / (f_max - f_min)\n",
    "    \n",
    "    n_filters = filters.shape[-1]\n",
    "    fig, axes = plt.subplots(1, n_filters, figsize=(20, 5))\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        f = filters[:, :, :, i]\n",
    "        axes[i].imshow(f[:, :, 0], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697ms/step\n",
      "Validation Accuracy: 0.6101694915254238\n",
      "Test Accuracy: 0.6101694915254238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming x_train, x_val, x_test, y_train, y_val, y_test are already defined\n",
    "# and have the shape (176, 20, 25000)\n",
    "\n",
    "# Build the CNN model for feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    return model\n",
    "\n",
    "input_shape = (20, 25000, 1)  # Adjusted to match the input data shape\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Reshape the data to add the channel dimension\n",
    "x_train = x_train.reshape(-1, 20, 25000, 1)\n",
    "x_val = x_val.reshape(-1, 20, 25000, 1)\n",
    "x_test = x_test.reshape(-1, 20, 25000, 1)\n",
    "\n",
    "\n",
    "# Extract features using the CNN model\n",
    "x_train_features = cnn_model.predict(x_train)\n",
    "x_val_features = cnn_model.predict(x_val)\n",
    "x_test_features = cnn_model.predict(x_test)\n",
    "\n",
    "# Train a RandomForestClassifier on the extracted features\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train_features, y_train.ravel())\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = rf_classifier.predict(x_val_features)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Test the model\n",
    "y_test_pred = rf_classifier.predict(x_test_features)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - accuracy: 0.0102 - loss: 16.0391 - val_accuracy: 0.0339 - val_loss: 15.7962\n",
      "Epoch 2/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.1204 - loss: 14.7456 - val_accuracy: 0.1525 - val_loss: 15.6711\n",
      "Epoch 3/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.2016 - loss: 15.8679 - val_accuracy: 0.1525 - val_loss: 15.6588\n",
      "Epoch 4/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.2429 - loss: 15.6973 - val_accuracy: 0.1525 - val_loss: 15.6586\n",
      "Epoch 5/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 5s/step - accuracy: 0.2065 - loss: 15.7634 - val_accuracy: 0.1525 - val_loss: 15.6585\n",
      "Epoch 6/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.2020 - loss: 16.4892 - val_accuracy: 0.1525 - val_loss: 15.6585\n",
      "Epoch 7/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 5s/step - accuracy: 0.2296 - loss: 16.1814 - val_accuracy: 0.1525 - val_loss: 15.6585\n",
      "Epoch 8/40\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.2585 - loss: 15.8427 - val_accuracy: 0.1525 - val_loss: 15.6585\n",
      "Epoch 9/40\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.1250 - loss: 13.7456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25000\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 31\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Extract features using the CNN model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m x_train_features \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mpredict(x_train)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming x_train, x_val, x_test, y_train, y_val, y_test are already defined\n",
    "# and have the shape (176, 20, 25000)\n",
    "\n",
    "# Build the CNN model for feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    return model\n",
    "\n",
    "input_shape = (20, 25000, 1)  # Adjusted to match the input data shape\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Reshape the data to add the channel dimension\n",
    "x_train = x_train.reshape(-1, 20, 25000, 1)\n",
    "x_val = x_val.reshape(-1, 20, 25000, 1)\n",
    "x_test = x_test.reshape(-1, 20, 25000, 1)\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "cnn_model.fit(x_train,y_train,epochs=40, batch_size=16, validation_data=(x_val, y_val))\n",
    "# Extract features using the CNN model\n",
    "x_train_features = cnn_model.predict(x_train)\n",
    "x_val_features = cnn_model.predict(x_val)\n",
    "x_test_features = cnn_model.predict(x_test)\n",
    "\n",
    "# Train a RandomForestClassifier on the extracted features\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train_features, y_train.ravel())\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = rf_classifier.predict(x_val_features)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Test the model\n",
    "y_test_pred = rf_classifier.predict(x_test_features)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "og model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the RBMLayer (assuming you have this implemented)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRBMLayer\u001b[39;00m(\u001b[43mlayers\u001b[49m\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_components):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(RBMLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the RBMLayer (assuming you have this implemented)\n",
    "class RBMLayer(layers.Layer):\n",
    "    def __init__(self, n_components):\n",
    "        super(RBMLayer, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        # Add your RBM layer initialization here\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Add your RBM layer logic here\n",
    "        return inputs\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    # Conv1D Layer: 64 filters, filter size of 5, stride of 1\n",
    "    model.add(layers.Conv1D(64, 5, activation='relu', strides=1, input_shape=input_shape))\n",
    "    # Pooling Layer: Pool size of 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # RBM Layer 1: 100 hidden units\n",
    "    rbm_layer1 = RBMLayer(n_components=100)\n",
    "    model.add(rbm_layer1)\n",
    "    \n",
    "    # RBM Layer 2: 50 hidden units\n",
    "    rbm_layer2 = RBMLayer(n_components=50)\n",
    "    model.add(rbm_layer2)\n",
    "    \n",
    "    # Fully Connected Layer: 128 units\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    \n",
    "    # Output Layer: Softmax with 6 units for each class\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (20, 25000)  # Adjusted to match the input data shape\n",
    "model = build_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ensure x_train and y_train are NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Check the shapes of x_train and y_train\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Ensure x_train is a 3D NumPy array\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4952 - loss: 1200.5188\n",
      "Test accuracy: 0.508474588394165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,000,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBMLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m8,000,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_6 (\u001b[38;5;33mRBMLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rbm_layer_7 (\u001b[38;5;33mRBMLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,199,508</span> (92.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,199,508\u001b[0m (92.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,066,502</span> (30.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,066,502\u001b[0m (30.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,133,006</span> (61.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,133,006\u001b[0m (61.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Accuracy: 0.5084745762711864\n",
      "Precision: 0.4589004451292587\n",
      "Recall: 0.5084745762711864\n",
      "F1 Score: 0.47380128450989095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.45      0.50        11\n",
      "           1       0.44      0.64      0.52        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.57      0.42         7\n",
      "           4       0.36      0.50      0.42         8\n",
      "           5       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.51        59\n",
      "   macro avg       0.43      0.50      0.46        59\n",
      "weighted avg       0.46      0.51      0.47        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kani1\\OneDrive\\Documents\\DS203 Programing for Data Science\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_test and y_test are your test data and labels\n",
    "X_test = x_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)  # Ensure y_test is integer type for sparse_categorical_crossentropy\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "model.summary()\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels if necessary\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Assuming X is your input data with shape (176, 20, 25000) and y is your labels with shape (176,)\n",
    "X = np.random.rand(176, 20, 25000)  # Replace with your actual data\n",
    "y = np.random.randint(0, 6, 176)    # Replace with your actual labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data to fit the CNN input requirements\n",
    "X_train = X_train.reshape(-1, 20, 25000, 1)\n",
    "X_test = X_test.reshape(-1, 20, 25000, 1)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(20, 25000, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu')\n",
    "    \n",
    "])\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
    "model.predict(x_train)\n",
    "# Extract features using the trained CNN model\n",
    "feature_extractor = tf.keras.Model(inputs=cnn_model.input, outputs=cnn_model.layers[-2].output)\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf_classifier.predict(X_test_features)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
