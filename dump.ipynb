{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE TO LOAD MIN-MAX POOLED MFCC FILES that are stored in a particular folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mfcc_files(directory):\n",
    "    mfcc_data = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('-MFCC.csv'):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            data = pd.read_csv(file_path, header=None).values\n",
    "            mfcc_data.append(data)\n",
    "    return mfcc_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for scalling and building the cdbn model(subject to hyper-parameter tunin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mfcc(mfccs):\n",
    "    \"\"\"\n",
    "    Preprocess MFCC features.\n",
    "    \n",
    "    Parameters:\n",
    "    mfccs (numpy.ndarray): The MFCC features.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The preprocessed MFCC features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    mfccs_scaled = scaler.fit_transform(mfccs)\n",
    "    mfccs_scaled = mfccs_scaled[np.newaxis, ..., np.newaxis]  # Add batch and channel dimensions\n",
    "    return mfccs_scaled\n",
    "\n",
    "\n",
    "def build_cdbn(input_shape):\n",
    "    \"\"\"\n",
    "    Build a Convolutional Deep Belief Network (CDBN).\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of the input data.\n",
    "    \n",
    "    Returns:\n",
    "    tensorflow.keras.Model: The CDBN model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))  # Adjust the number of classes as needed\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to visualize what cdbn is doing (subject to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, layer_name, input_data):\n",
    "    \"\"\"\n",
    "    Visualize the feature maps of a convolutional layer.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the convolutional layer.\n",
    "    input_data (numpy.ndarray): The input data.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    feature_map_model = models.Model(inputs=model.input, outputs=layer.output)\n",
    "    feature_maps = feature_map_model.predict(input_data)\n",
    "    \n",
    "    n_features = feature_maps.shape[-1]\n",
    "    fig, axes = plt.subplots(1, n_features, figsize=(20, 5))\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        axes[i].imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def visualize_filters(model, layer_name):\n",
    "    \"\"\"\n",
    "    Visualize the filters of a convolutional layer.\n",
    "    \n",
    "    Parameters:\n",
    "    model (tensorflow.keras.Model): The trained model.\n",
    "    layer_name (str): The name of the convolutional layer.\n",
    "    \"\"\"\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    filters, biases = layer.get_weights()\n",
    "    \n",
    "    # Normalize filter values to 0-1 so we can visualize them\n",
    "    f_min, f_max = filters.min(), filters.max()\n",
    "    filters = (filters - f_min) / (f_max - f_min)\n",
    "    \n",
    "    n_filters = filters.shape[-1]\n",
    "    fig, axes = plt.subplots(1, n_filters, figsize=(20, 5))\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        f = filters[:, :, :, i]\n",
    "        axes[i].imshow(f[:, :, 0], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 20, 25000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = \"C:\\\\Users\\\\kani1\\\\OneDrive\\\\Documents\\\\DS203 Programing for Data Science\\\\project\\\\mfcc_processed\" #path of the folder which contains the min-max pooled mfcc files\n",
    "mfcc_data = load_mfcc_files(directory)\n",
    "\n",
    "mfcc_data_combined = np.array(mfcc_data)\n",
    "\n",
    "# Print the shape of the combined numpy array\n",
    "print(mfcc_data_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_preprocessed = preprocess_mfcc(mfccs_data_combined)\n",
    "input_shape = mfccs_preprocessed.shape[1:]\n",
    "cdbn_model = build_cdbn(input_shape)\n",
    "cdbn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "X_train = np.array([0])  # Replace with actual data\n",
    "y_train = np.array([0])  # Replace with actual labels\n",
    "\n",
    "# Train the model\n",
    "cdbn_model.fit(X_train, y_train, epochs=10, batch_size=1)\n",
    "\n",
    "visualize_filters(cdbn_model, 'conv2d')\n",
    "visualize_feature_maps(cdbn_model, 'conv2d', mfccs_preprocessed)\n",
    "\n",
    "# Predict on new data\n",
    "X_test = np.array([0])  # Replace with actual test data\n",
    "predictions = cdbn_model.predict(X_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
